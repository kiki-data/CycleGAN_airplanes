{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From https://github.com/MingtaoGuo/CycleGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:174: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, d_loss_X: 0.437471, d_loss_Y: -1.7111, g_loss_X: 1017.31, g_loss_Y: 1017.38, cyc_loss: 101.777\n",
      "epoch: 1, step: 0, d_loss_X: -7.01107, d_loss_Y: -4.37815, g_loss_X: 702.064, g_loss_Y: 702.138, cyc_loss: 70.0341\n",
      "epoch: 2, step: 0, d_loss_X: -24.4539, d_loss_Y: -4.7207, g_loss_X: 645.386, g_loss_Y: 628.122, cyc_loss: 62.685\n",
      "epoch: 3, step: 0, d_loss_X: -5.18433, d_loss_Y: -15.3202, g_loss_X: 603.755, g_loss_Y: 598.063, cyc_loss: 60.368\n",
      "epoch: 4, step: 0, d_loss_X: -16.6411, d_loss_Y: 7.04537, g_loss_X: 665.387, g_loss_Y: 633.41, cyc_loss: 65.1366\n",
      "epoch: 5, step: 0, d_loss_X: 9.99807, d_loss_Y: -17.3417, g_loss_X: 515.9, g_loss_Y: 531.438, cyc_loss: 54.2898\n",
      "epoch: 6, step: 0, d_loss_X: -15.0726, d_loss_Y: -36.8993, g_loss_X: 532.689, g_loss_Y: 534.56, cyc_loss: 52.837\n",
      "epoch: 7, step: 0, d_loss_X: -15.0219, d_loss_Y: -8.58224, g_loss_X: 609.27, g_loss_Y: 595.251, cyc_loss: 60.1536\n",
      "epoch: 8, step: 0, d_loss_X: -8.45016, d_loss_Y: -34.0765, g_loss_X: 572.371, g_loss_Y: 562.982, cyc_loss: 56.1903\n",
      "epoch: 9, step: 0, d_loss_X: -10.6241, d_loss_Y: -47.9852, g_loss_X: 577.642, g_loss_Y: 590.405, cyc_loss: 56.4462\n",
      "epoch: 10, step: 0, d_loss_X: -11.242, d_loss_Y: -5.81167, g_loss_X: 576.423, g_loss_Y: 550.627, cyc_loss: 57.5165\n",
      "epoch: 11, step: 0, d_loss_X: -46.0237, d_loss_Y: 18.6317, g_loss_X: 578.998, g_loss_Y: 538.48, cyc_loss: 56.6392\n",
      "epoch: 12, step: 0, d_loss_X: -14.5205, d_loss_Y: -31.8865, g_loss_X: 477.041, g_loss_Y: 466.018, cyc_loss: 47.4257\n",
      "epoch: 13, step: 0, d_loss_X: -4.36777, d_loss_Y: -10.142, g_loss_X: 565.534, g_loss_Y: 519.278, cyc_loss: 52.7888\n",
      "epoch: 14, step: 0, d_loss_X: -14.7792, d_loss_Y: -36.4378, g_loss_X: 493.432, g_loss_Y: 465.095, cyc_loss: 45.8963\n",
      "epoch: 15, step: 0, d_loss_X: -50.9419, d_loss_Y: -9.33981, g_loss_X: 605.34, g_loss_Y: 535.759, cyc_loss: 56.9294\n",
      "epoch: 16, step: 0, d_loss_X: -34.6495, d_loss_Y: -35.9133, g_loss_X: 484.108, g_loss_Y: 480.468, cyc_loss: 49.398\n",
      "epoch: 17, step: 0, d_loss_X: -57.9757, d_loss_Y: -31.4046, g_loss_X: 442.372, g_loss_Y: 462.274, cyc_loss: 42.6433\n",
      "epoch: 18, step: 0, d_loss_X: -26.4244, d_loss_Y: -8.88758, g_loss_X: 438.396, g_loss_Y: 492.764, cyc_loss: 45.123\n",
      "epoch: 19, step: 0, d_loss_X: -42.9412, d_loss_Y: -68.9856, g_loss_X: 434.827, g_loss_Y: 463.954, cyc_loss: 42.6045\n",
      "epoch: 20, step: 0, d_loss_X: -11.2028, d_loss_Y: -31.6519, g_loss_X: 346.679, g_loss_Y: 355.58, cyc_loss: 37.9679\n",
      "epoch: 21, step: 0, d_loss_X: -31.287, d_loss_Y: -66.678, g_loss_X: 486.205, g_loss_Y: 462.828, cyc_loss: 43.5017\n",
      "epoch: 22, step: 0, d_loss_X: -29.466, d_loss_Y: -23.5152, g_loss_X: 540.201, g_loss_Y: 454.714, cyc_loss: 49.4727\n",
      "epoch: 23, step: 0, d_loss_X: -30.0537, d_loss_Y: -53.9325, g_loss_X: 411.547, g_loss_Y: 392.37, cyc_loss: 36.1618\n",
      "epoch: 24, step: 0, d_loss_X: -48.8507, d_loss_Y: -65.5757, g_loss_X: 425.453, g_loss_Y: 424.916, cyc_loss: 37.6738\n",
      "epoch: 25, step: 0, d_loss_X: -38.8784, d_loss_Y: -59.8284, g_loss_X: 446.687, g_loss_Y: 394.535, cyc_loss: 39.5642\n",
      "epoch: 26, step: 0, d_loss_X: -3.41209, d_loss_Y: -55.8567, g_loss_X: 442.077, g_loss_Y: 436.28, cyc_loss: 37.9955\n",
      "epoch: 27, step: 0, d_loss_X: -50.6335, d_loss_Y: -19.7424, g_loss_X: 442.066, g_loss_Y: 368.032, cyc_loss: 41.1146\n",
      "epoch: 28, step: 0, d_loss_X: -49.9136, d_loss_Y: -38.3015, g_loss_X: 400.205, g_loss_Y: 456.312, cyc_loss: 39.9686\n",
      "epoch: 29, step: 0, d_loss_X: -67.1565, d_loss_Y: -69.5973, g_loss_X: 404.584, g_loss_Y: 392.302, cyc_loss: 38.5484\n",
      "epoch: 30, step: 0, d_loss_X: -52.6249, d_loss_Y: -76.6131, g_loss_X: 428.413, g_loss_Y: 498.103, cyc_loss: 44.1512\n",
      "epoch: 31, step: 0, d_loss_X: -44.6891, d_loss_Y: -55.3575, g_loss_X: 349.186, g_loss_Y: 362.924, cyc_loss: 36.8315\n",
      "epoch: 32, step: 0, d_loss_X: -52.9862, d_loss_Y: -8.32104, g_loss_X: 360.676, g_loss_Y: 422.661, cyc_loss: 35.6964\n",
      "epoch: 33, step: 0, d_loss_X: -68.0996, d_loss_Y: -73.2312, g_loss_X: 424.161, g_loss_Y: 434.928, cyc_loss: 41.8835\n",
      "epoch: 34, step: 0, d_loss_X: -59.2873, d_loss_Y: -75.8158, g_loss_X: 465.723, g_loss_Y: 454.231, cyc_loss: 41.9476\n",
      "epoch: 35, step: 0, d_loss_X: -82.2366, d_loss_Y: -78.6072, g_loss_X: 435.425, g_loss_Y: 475.806, cyc_loss: 41.5536\n",
      "epoch: 36, step: 0, d_loss_X: -79.6076, d_loss_Y: -88.7354, g_loss_X: 474.527, g_loss_Y: 475.583, cyc_loss: 45.7921\n",
      "epoch: 37, step: 0, d_loss_X: -58.5637, d_loss_Y: -92.0283, g_loss_X: 374.04, g_loss_Y: 382.491, cyc_loss: 35.4162\n",
      "epoch: 38, step: 0, d_loss_X: -105.692, d_loss_Y: -112.415, g_loss_X: 466.602, g_loss_Y: 474.566, cyc_loss: 42.8446\n",
      "epoch: 39, step: 0, d_loss_X: -85.6072, d_loss_Y: -49.5007, g_loss_X: 422.851, g_loss_Y: 338.388, cyc_loss: 35.9281\n",
      "epoch: 40, step: 0, d_loss_X: -100.725, d_loss_Y: -51.9816, g_loss_X: 459.511, g_loss_Y: 369.041, cyc_loss: 39.1928\n",
      "epoch: 41, step: 0, d_loss_X: -119.196, d_loss_Y: -84.1471, g_loss_X: 417.803, g_loss_Y: 414.476, cyc_loss: 36.208\n",
      "epoch: 42, step: 0, d_loss_X: -71.5777, d_loss_Y: -112.065, g_loss_X: 336.373, g_loss_Y: 364.582, cyc_loss: 30.4903\n",
      "epoch: 43, step: 0, d_loss_X: -58.7992, d_loss_Y: -77.5567, g_loss_X: 365.712, g_loss_Y: 423.419, cyc_loss: 36.7185\n",
      "epoch: 44, step: 0, d_loss_X: -75.9016, d_loss_Y: -50.654, g_loss_X: 402.301, g_loss_Y: 322.079, cyc_loss: 34.7661\n",
      "epoch: 45, step: 0, d_loss_X: -66.6725, d_loss_Y: -52.4732, g_loss_X: 391.506, g_loss_Y: 328.337, cyc_loss: 33.4853\n",
      "epoch: 46, step: 0, d_loss_X: -38.6099, d_loss_Y: -85.4193, g_loss_X: 402.361, g_loss_Y: 393.216, cyc_loss: 33.0201\n",
      "epoch: 47, step: 0, d_loss_X: -39.7598, d_loss_Y: -47.8503, g_loss_X: 437.303, g_loss_Y: 493.265, cyc_loss: 42.2835\n",
      "epoch: 48, step: 0, d_loss_X: -2.23466, d_loss_Y: -30.451, g_loss_X: 456.916, g_loss_Y: 460.953, cyc_loss: 40.1414\n",
      "epoch: 49, step: 0, d_loss_X: -64.8373, d_loss_Y: -15.7586, g_loss_X: 447.309, g_loss_Y: 350.047, cyc_loss: 40.8819\n",
      "epoch: 50, step: 0, d_loss_X: -109.057, d_loss_Y: -25.3089, g_loss_X: 501.275, g_loss_Y: 511.169, cyc_loss: 44.2311\n",
      "epoch: 51, step: 0, d_loss_X: -7.56281, d_loss_Y: 8.50497, g_loss_X: 397.811, g_loss_Y: 345.442, cyc_loss: 32.69\n",
      "epoch: 52, step: 0, d_loss_X: -28.0693, d_loss_Y: -27.9537, g_loss_X: 426.683, g_loss_Y: 404.105, cyc_loss: 35.3492\n",
      "epoch: 53, step: 0, d_loss_X: -57.1344, d_loss_Y: -71.2606, g_loss_X: 414.887, g_loss_Y: 461.839, cyc_loss: 42.611\n",
      "epoch: 54, step: 0, d_loss_X: -52.2398, d_loss_Y: -68.316, g_loss_X: 442.524, g_loss_Y: 417.119, cyc_loss: 37.6307\n",
      "epoch: 55, step: 0, d_loss_X: -41.4754, d_loss_Y: -32.592, g_loss_X: 400.615, g_loss_Y: 329.153, cyc_loss: 34.2078\n",
      "epoch: 56, step: 0, d_loss_X: -31.4557, d_loss_Y: -84.592, g_loss_X: 403.317, g_loss_Y: 370.697, cyc_loss: 33.0151\n",
      "epoch: 57, step: 0, d_loss_X: -75.3174, d_loss_Y: -32.705, g_loss_X: 386.048, g_loss_Y: 299.547, cyc_loss: 33.9719\n",
      "epoch: 58, step: 0, d_loss_X: -16.468, d_loss_Y: -47.4061, g_loss_X: 293.478, g_loss_Y: 412.584, cyc_loss: 35.1886\n",
      "epoch: 59, step: 0, d_loss_X: -70.0387, d_loss_Y: -71.0481, g_loss_X: 412.593, g_loss_Y: 454.996, cyc_loss: 41.5293\n",
      "epoch: 60, step: 0, d_loss_X: -49.8061, d_loss_Y: -68.1164, g_loss_X: 342.676, g_loss_Y: 417.094, cyc_loss: 36.1167\n",
      "epoch: 61, step: 0, d_loss_X: -10.7084, d_loss_Y: -48.7131, g_loss_X: 396.906, g_loss_Y: 407.96, cyc_loss: 35.6966\n",
      "epoch: 62, step: 0, d_loss_X: -4.54633, d_loss_Y: -11.1765, g_loss_X: 425.429, g_loss_Y: 296.706, cyc_loss: 34.9351\n",
      "epoch: 63, step: 0, d_loss_X: -9.70602, d_loss_Y: 2.28341, g_loss_X: 273.067, g_loss_Y: 396.744, cyc_loss: 32.3706\n",
      "epoch: 64, step: 0, d_loss_X: -15.478, d_loss_Y: -5.0541, g_loss_X: 264.837, g_loss_Y: 247.574, cyc_loss: 32.1104\n",
      "epoch: 65, step: 0, d_loss_X: -49.1209, d_loss_Y: -106.774, g_loss_X: 463.554, g_loss_Y: 468.988, cyc_loss: 41.72\n",
      "epoch: 66, step: 0, d_loss_X: -15.4186, d_loss_Y: -9.02256, g_loss_X: 385.362, g_loss_Y: 260.304, cyc_loss: 31.6204\n",
      "epoch: 67, step: 0, d_loss_X: 35.6597, d_loss_Y: -24.59, g_loss_X: 314.496, g_loss_Y: 327.005, cyc_loss: 36.8677\n",
      "epoch: 68, step: 0, d_loss_X: -22.1354, d_loss_Y: -49.1684, g_loss_X: 331.644, g_loss_Y: 435.607, cyc_loss: 38.381\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "epsilon = 1e-8\n",
    "img_W = 128\n",
    "img_H = 128\n",
    "img_nums = 8000\n",
    "batchsize = 5\n",
    "\n",
    "\n",
    "def conv(inputs, nums_out, ksize, stride, padding, is_dis=False):\n",
    "    c = int(inputs.shape[-1])\n",
    "    W = tf.get_variable(\"W\", shape=[ksize, ksize, c, nums_out], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(\"b\", shape=[nums_out], initializer=tf.constant_initializer([0]))\n",
    "    if is_dis:\n",
    "        return tf.nn.conv2d(inputs, spectral_norm(\"SN\",W), [1, stride, stride, 1], padding) + b\n",
    "    else:\n",
    "        return tf.nn.conv2d(inputs, W, [1, stride, stride, 1], padding) + b\n",
    "\n",
    "def deconv(inputs, nums_out, ksize, stride):\n",
    "    c = int(inputs.shape[-1])\n",
    "    batch = int(inputs.shape[0])\n",
    "    height = int(inputs.shape[1])\n",
    "    width = int(inputs.shape[2])\n",
    "    W = tf.get_variable(\"W\", shape=[ksize, ksize, nums_out, c], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(\"b\", shape=[nums_out], initializer=tf.constant_initializer([0.]))\n",
    "    return tf.nn.conv2d_transpose(inputs, W, output_shape=[batch, height*stride, width*stride, nums_out], strides=[1, stride, stride, 1]) + b\n",
    "\n",
    "def InstanceNorm(inputs):\n",
    "    mean, var = tf.nn.moments(inputs, axes=[1, 2], keep_dims=True)\n",
    "    scale = tf.get_variable(\"scale\", shape=mean.shape[-1], initializer=tf.constant_initializer([1.]))\n",
    "    shift = tf.get_variable(\"shift\", shape=mean.shape[-1], initializer=tf.constant_initializer([0.]))\n",
    "    return (inputs - mean) * scale / tf.sqrt(var + epsilon) + shift\n",
    "\n",
    "def leaky_relu(inputs, slope=0.2):\n",
    "    return tf.maximum(slope*inputs, inputs)\n",
    "\n",
    "def spectral_norm(name, w, iteration=1):\n",
    "    #Spectral normalization which was published on ICLR2018,please refer to \"https://www.researchgate.net/publication/318572189_Spectral_Normalization_for_Generative_Adversarial_Networks\"\n",
    "    #This function spectral_norm is forked from \"https://github.com/taki0112/Spectral_Normalization-Tensorflow\"\n",
    "    w_shape = w.shape.as_list()\n",
    "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
    "    with tf.variable_scope(name, reuse=False):\n",
    "        u = tf.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n",
    "    u_hat = u\n",
    "    v_hat = None\n",
    "\n",
    "    def l2_norm(v, eps=1e-12):\n",
    "        return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)\n",
    "\n",
    "    for i in range(iteration):\n",
    "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
    "        v_hat = l2_norm(v_)\n",
    "        u_ = tf.matmul(v_hat, w)\n",
    "        u_hat = l2_norm(u_)\n",
    "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
    "    w_norm = w / sigma\n",
    "    with tf.control_dependencies([u.assign(u_hat)]):\n",
    "        w_norm = tf.reshape(w_norm, w_shape)\n",
    "    return w_norm\n",
    "\n",
    "\n",
    "class discriminator:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, inputs, reuse = False):\n",
    "        #Patch discriminator\n",
    "        inputs = tf.random_crop(inputs, [batchsize, 70, 70, 3])\n",
    "        with tf.variable_scope(self.name, reuse=reuse):\n",
    "            with tf.variable_scope(\"c64\"):\n",
    "                inputs = leaky_relu(conv(inputs, 64, 5, 2, \"SAME\", True))\n",
    "            with tf.variable_scope(\"c128\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 128, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"c256\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 256, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"c512\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 512, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"fully_conv\"):\n",
    "                ksize = np.size(inputs, 1)\n",
    "                inputs = tf.squeeze(conv(inputs, 1, ksize, 1, \"VALID\", True), axis=[1, 2, 3])\n",
    "        return inputs\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "\n",
    "\n",
    "class generator:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, inputs, reuse=False):\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=reuse):\n",
    "            inputs = tf.pad(inputs, tf.constant([[0, 0], [3, 3], [3, 3], [0, 0]]))\n",
    "            with tf.variable_scope(\"c7s1-32\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 32, 7, 1, \"VALID\")))\n",
    "            with tf.variable_scope(\"d64\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 64, 3, 2, \"SAME\")))\n",
    "            with tf.variable_scope(\"d128\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 128, 3, 2, \"SAME\")))\n",
    "            for i in range(6):\n",
    "                with tf.variable_scope(\"R\"+str(i)):\n",
    "                    temp = inputs\n",
    "                    with tf.variable_scope(\"R_conv1\"):\n",
    "                        inputs = tf.pad(inputs, tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]]), \"REFLECT\")\n",
    "                        inputs = tf.nn.relu(InstanceNorm(conv(inputs, 128, 3, 1, \"VALID\")))\n",
    "                    with tf.variable_scope(\"R_conv2\"):\n",
    "                        inputs = tf.pad(inputs, tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]]), \"REFLECT\")\n",
    "                        inputs = InstanceNorm(conv(inputs, 128, 3, 1, \"VALID\"))\n",
    "                    inputs = temp + inputs\n",
    "            with tf.variable_scope(\"u64\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(deconv(inputs, 64, 3, 2)))\n",
    "            with tf.variable_scope(\"u32\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(deconv(inputs, 32, 3, 2)))\n",
    "            with tf.variable_scope(\"c7s1-3\"):\n",
    "                inputs = tf.nn.tanh((deconv(inputs, 3, 7, 1)))\n",
    "            return (inputs + 1.) * 127.5\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "\n",
    "class CycleGAN:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(\"float\", shape=[batchsize, img_H, img_W, 3])\n",
    "        self.Y = tf.placeholder(\"float\", shape=[batchsize, img_H, img_W, 3])\n",
    "        G = generator(\"G\")\n",
    "        F = generator(\"F\")\n",
    "        self.Dx = discriminator(\"Dx\")\n",
    "        self.Dy = discriminator(\"Dy\")\n",
    "        self.fake_X = F(self.Y)\n",
    "        self.fake_Y = G(self.X)\n",
    "        self.logits_real_X = self.Dx(self.X)\n",
    "        self.logits_real_Y = self.Dy(self.Y)\n",
    "        self.logits_fake_X = self.Dx(self.fake_X, True)\n",
    "        self.logits_fake_Y = self.Dy(self.fake_Y, True)\n",
    "        self.L_cyc = tf.reduce_mean(tf.abs(F(self.fake_Y, True) - self.X)) + tf.reduce_mean(tf.abs(G(self.fake_X, True) - self.Y))\n",
    "        #WGAN's Loss function is used here, which is different from the paper CycleGAN where used LSGAN's loss function\n",
    "        #WGAN has been proved that it can yield high quality result and make the training process more stable\n",
    "        self.d_loss_Y = -tf.reduce_mean(self.logits_real_Y) + tf.reduce_mean(self.logits_fake_Y)\n",
    "        self.d_loss_X = -tf.reduce_mean(self.logits_real_X) + tf.reduce_mean(self.logits_fake_X)\n",
    "        self.g_loss_Y = -tf.reduce_mean(self.logits_fake_Y) + 10. * self.L_cyc\n",
    "        self.g_loss_X = -tf.reduce_mean(self.logits_fake_X) + 10. * self.L_cyc\n",
    "        self.Dx_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.d_loss_X, var_list=[self.Dx.var])\n",
    "        self.Dy_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.d_loss_Y, var_list=[self.Dy.var])\n",
    "        self.G_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.g_loss_Y, var_list=[G.var])\n",
    "        self.F_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.g_loss_X, var_list=[F.var])\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.train()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        Y_path = \"./Y//\"\n",
    "        X_path = \"./X//\"\n",
    "        Y = os.listdir(Y_path)[:img_nums]\n",
    "        X = os.listdir(X_path)[:img_nums]\n",
    "        nums = Y.__len__()\n",
    "        saver = tf.train.Saver()\n",
    "        for epoch in range(100):\n",
    "            for i in range(int(nums / batchsize) - 1):\n",
    "                X_img = np.zeros([batchsize, img_H, img_W, 3])\n",
    "                Y_img = np.zeros([batchsize, img_H, img_W, 3])\n",
    "                for j in np.arange(i * batchsize, i * batchsize + batchsize, 1):\n",
    "                    img = misc.imresize(np.array(Image.open(X_path + X[j])), [img_H, img_W])\n",
    "                    X_img[j - i * batchsize, :, :, :] = img\n",
    "                    img = misc.imresize(np.array(Image.open(Y_path + Y[j])), [img_H, img_W])\n",
    "                    Y_img[j - i * batchsize, :, :, :] = img\n",
    "                self.sess.run(self.Dy_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.Dx_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.G_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.F_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                if i % 10 == 0:\n",
    "                    [d_loss_X, d_loss_Y, g_loss_Y, g_loss_X, fake_X, fake_Y, cyc_loss] = \\\n",
    "                        self.sess.run([self.d_loss_X, self.d_loss_Y, self.g_loss_Y, self.g_loss_X, self.fake_X, self.fake_Y, self.L_cyc], feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                    print(\"epoch: %d, step: %d, d_loss_X: %g, d_loss_Y: %g, g_loss_X: %g, g_loss_Y: %g, cyc_loss: %g\"%(epoch, i, d_loss_X, d_loss_Y, g_loss_X, g_loss_Y, cyc_loss))\n",
    "                    Image.fromarray(np.uint8(fake_Y)[0, :, :, :]).save(\".//fake_Y//\"+str(epoch)+\"_\"+str(i)+\".jpg\")\n",
    "                    Image.fromarray(np.uint8(fake_X)[0, :, :, :]).save(\".//fake_X//\" + str(epoch) + \"_\" + str(i) + \".jpg\")\n",
    "            saver.save(self.sess, \"./save_para//CycleGAN_airplanes.ckpt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cyc = CycleGAN()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
