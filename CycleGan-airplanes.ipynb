{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From https://github.com/MingtaoGuo/CycleGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "epsilon = 1e-8\n",
    "img_W = 128\n",
    "img_H = 128\n",
    "img_nums = 8000\n",
    "batchsize = 5\n",
    "\n",
    "\n",
    "def conv(inputs, nums_out, ksize, stride, padding, is_dis=False):\n",
    "    c = int(inputs.shape[-1])\n",
    "    W = tf.get_variable(\"W\", shape=[ksize, ksize, c, nums_out], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(\"b\", shape=[nums_out], initializer=tf.constant_initializer([0]))\n",
    "    if is_dis:\n",
    "        return tf.nn.conv2d(inputs, spectral_norm(\"SN\",W), [1, stride, stride, 1], padding) + b\n",
    "    else:\n",
    "        return tf.nn.conv2d(inputs, W, [1, stride, stride, 1], padding) + b\n",
    "\n",
    "def deconv(inputs, nums_out, ksize, stride):\n",
    "    c = int(inputs.shape[-1])\n",
    "    batch = int(inputs.shape[0])\n",
    "    height = int(inputs.shape[1])\n",
    "    width = int(inputs.shape[2])\n",
    "    W = tf.get_variable(\"W\", shape=[ksize, ksize, nums_out, c], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(\"b\", shape=[nums_out], initializer=tf.constant_initializer([0.]))\n",
    "    return tf.nn.conv2d_transpose(inputs, W, output_shape=[batch, height*stride, width*stride, nums_out], strides=[1, stride, stride, 1]) + b\n",
    "\n",
    "def InstanceNorm(inputs):\n",
    "    mean, var = tf.nn.moments(inputs, axes=[1, 2], keep_dims=True)\n",
    "    scale = tf.get_variable(\"scale\", shape=mean.shape[-1], initializer=tf.constant_initializer([1.]))\n",
    "    shift = tf.get_variable(\"shift\", shape=mean.shape[-1], initializer=tf.constant_initializer([0.]))\n",
    "    return (inputs - mean) * scale / tf.sqrt(var + epsilon) + shift\n",
    "\n",
    "def leaky_relu(inputs, slope=0.2):\n",
    "    return tf.maximum(slope*inputs, inputs)\n",
    "\n",
    "def spectral_norm(name, w, iteration=1):\n",
    "    #Spectral normalization which was published on ICLR2018,please refer to \"https://www.researchgate.net/publication/318572189_Spectral_Normalization_for_Generative_Adversarial_Networks\"\n",
    "    #This function spectral_norm is forked from \"https://github.com/taki0112/Spectral_Normalization-Tensorflow\"\n",
    "    w_shape = w.shape.as_list()\n",
    "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
    "    with tf.variable_scope(name, reuse=False):\n",
    "        u = tf.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n",
    "    u_hat = u\n",
    "    v_hat = None\n",
    "\n",
    "    def l2_norm(v, eps=1e-12):\n",
    "        return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)\n",
    "\n",
    "    for i in range(iteration):\n",
    "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
    "        v_hat = l2_norm(v_)\n",
    "        u_ = tf.matmul(v_hat, w)\n",
    "        u_hat = l2_norm(u_)\n",
    "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
    "    w_norm = w / sigma\n",
    "    with tf.control_dependencies([u.assign(u_hat)]):\n",
    "        w_norm = tf.reshape(w_norm, w_shape)\n",
    "    return w_norm\n",
    "\n",
    "\n",
    "class discriminator:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, inputs, reuse = False):\n",
    "        #Patch discriminator\n",
    "        inputs = tf.random_crop(inputs, [batchsize, 70, 70, 3])\n",
    "        with tf.variable_scope(self.name, reuse=reuse):\n",
    "            with tf.variable_scope(\"c64\"):\n",
    "                inputs = leaky_relu(conv(inputs, 64, 5, 2, \"SAME\", True))\n",
    "            with tf.variable_scope(\"c128\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 128, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"c256\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 256, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"c512\"):\n",
    "                inputs = leaky_relu(InstanceNorm(conv(inputs, 512, 5, 2, \"SAME\", True)))\n",
    "            with tf.variable_scope(\"fully_conv\"):\n",
    "                ksize = np.size(inputs, 1)\n",
    "                inputs = tf.squeeze(conv(inputs, 1, ksize, 1, \"VALID\", True), axis=[1, 2, 3])\n",
    "        return inputs\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "\n",
    "\n",
    "class generator:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, inputs, reuse=False):\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=reuse):\n",
    "            inputs = tf.pad(inputs, tf.constant([[0, 0], [3, 3], [3, 3], [0, 0]]))\n",
    "            with tf.variable_scope(\"c7s1-32\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 32, 7, 1, \"VALID\")))\n",
    "            with tf.variable_scope(\"d64\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 64, 3, 2, \"SAME\")))\n",
    "            with tf.variable_scope(\"d128\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(conv(inputs, 128, 3, 2, \"SAME\")))\n",
    "            for i in range(6):\n",
    "                with tf.variable_scope(\"R\"+str(i)):\n",
    "                    temp = inputs\n",
    "                    with tf.variable_scope(\"R_conv1\"):\n",
    "                        inputs = tf.pad(inputs, tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]]), \"REFLECT\")\n",
    "                        inputs = tf.nn.relu(InstanceNorm(conv(inputs, 128, 3, 1, \"VALID\")))\n",
    "                    with tf.variable_scope(\"R_conv2\"):\n",
    "                        inputs = tf.pad(inputs, tf.constant([[0, 0], [1, 1], [1, 1], [0, 0]]), \"REFLECT\")\n",
    "                        inputs = InstanceNorm(conv(inputs, 128, 3, 1, \"VALID\"))\n",
    "                    inputs = temp + inputs\n",
    "            with tf.variable_scope(\"u64\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(deconv(inputs, 64, 3, 2)))\n",
    "            with tf.variable_scope(\"u32\"):\n",
    "                inputs = tf.nn.relu(InstanceNorm(deconv(inputs, 32, 3, 2)))\n",
    "            with tf.variable_scope(\"c7s1-3\"):\n",
    "                inputs = tf.nn.tanh((deconv(inputs, 3, 7, 1)))\n",
    "            return (inputs + 1.) * 127.5\n",
    "\n",
    "    @property\n",
    "    def var(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "\n",
    "class CycleGAN:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(\"float\", shape=[batchsize, img_H, img_W, 3])\n",
    "        self.Y = tf.placeholder(\"float\", shape=[batchsize, img_H, img_W, 3])\n",
    "        G = generator(\"G\")\n",
    "        F = generator(\"F\")\n",
    "        self.Dx = discriminator(\"Dx\")\n",
    "        self.Dy = discriminator(\"Dy\")\n",
    "        self.fake_X = F(self.Y)\n",
    "        self.fake_Y = G(self.X)\n",
    "        self.logits_real_X = self.Dx(self.X)\n",
    "        self.logits_real_Y = self.Dy(self.Y)\n",
    "        self.logits_fake_X = self.Dx(self.fake_X, True)\n",
    "        self.logits_fake_Y = self.Dy(self.fake_Y, True)\n",
    "        self.L_cyc = tf.reduce_mean(tf.abs(F(self.fake_Y, True) - self.X)) + tf.reduce_mean(tf.abs(G(self.fake_X, True) - self.Y))\n",
    "        #WGAN's Loss function is used here, which is different from the paper CycleGAN where used LSGAN's loss function\n",
    "        #WGAN has been proved that it can yield high quality result and make the training process more stable\n",
    "        self.d_loss_Y = -tf.reduce_mean(self.logits_real_Y) + tf.reduce_mean(self.logits_fake_Y)\n",
    "        self.d_loss_X = -tf.reduce_mean(self.logits_real_X) + tf.reduce_mean(self.logits_fake_X)\n",
    "        self.g_loss_Y = -tf.reduce_mean(self.logits_fake_Y) + 10. * self.L_cyc\n",
    "        self.g_loss_X = -tf.reduce_mean(self.logits_fake_X) + 10. * self.L_cyc\n",
    "        self.Dx_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.d_loss_X, var_list=[self.Dx.var])\n",
    "        self.Dy_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.d_loss_Y, var_list=[self.Dy.var])\n",
    "        self.G_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.g_loss_Y, var_list=[G.var])\n",
    "        self.F_opt = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.g_loss_X, var_list=[F.var])\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.train()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        Y_path = \"./Y//\"\n",
    "        X_path = \"./X//\"\n",
    "        Y = os.listdir(Y_path)[:img_nums]\n",
    "        X = os.listdir(X_path)[:img_nums]\n",
    "        nums = Y.__len__()\n",
    "        saver = tf.train.Saver()\n",
    "        for epoch in range(100):\n",
    "            for i in range(int(nums / batchsize) - 1):\n",
    "                X_img = np.zeros([batchsize, img_H, img_W, 3])\n",
    "                Y_img = np.zeros([batchsize, img_H, img_W, 3])\n",
    "                for j in np.arange(i * batchsize, i * batchsize + batchsize, 1):\n",
    "                    img = misc.imresize(np.array(Image.open(X_path + X[j])), [img_H, img_W])\n",
    "                    X_img[j - i * batchsize, :, :, :] = img\n",
    "                    img = misc.imresize(np.array(Image.open(Y_path + Y[j])), [img_H, img_W])\n",
    "                    Y_img[j - i * batchsize, :, :, :] = img\n",
    "                self.sess.run(self.Dy_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.Dx_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.G_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                self.sess.run(self.F_opt, feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                if i % 10 == 0:\n",
    "                    [d_loss_X, d_loss_Y, g_loss_Y, g_loss_X, fake_X, fake_Y, cyc_loss] = \\\n",
    "                        self.sess.run([self.d_loss_X, self.d_loss_Y, self.g_loss_Y, self.g_loss_X, self.fake_X, self.fake_Y, self.L_cyc], feed_dict={self.X: X_img, self.Y: Y_img})\n",
    "                    print(\"epoch: %d, step: %d, d_loss_X: %g, d_loss_Y: %g, g_loss_X: %g, g_loss_Y: %g, cyc_loss: %g\"%(epoch, i, d_loss_X, d_loss_Y, g_loss_X, g_loss_Y, cyc_loss))\n",
    "                    Image.fromarray(np.uint8(fake_Y)[0, :, :, :]).save(\".//fake_Y//\"+str(epoch)+\"_\"+str(i)+\".jpg\")\n",
    "                    Image.fromarray(np.uint8(fake_X)[0, :, :, :]).save(\".//fake_X//\" + str(epoch) + \"_\" + str(i) + \".jpg\")\n",
    "            saver.save(self.sess, \"./save_para//CycleGAN_airplanes.ckpt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cyc = CycleGAN()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
